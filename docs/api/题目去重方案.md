# 题目重复性排查方案

## 一、方案概述

### 1.1 目标

对 50 万条题目进行重复性排查，找出"长得差不多"的题目，并计算重复程度。

### 1.2 核心思想

采用**局部敏感哈希（LSH）**和**MinHash**算法，通过"指纹+分桶"的方式，避免两两比对（O(n²)），将时间复杂度降低到 O(n)。

**核心策略**：

- 不是两两比对，而是给每道题打指纹，按指纹分组
- 只比对同组的题，不同组的题一定不重复
- 先快速去掉完全一样的，再把剩下的题按"可能重复"分组
- 最后只在小组里算谁和谁有多像

### 1.3 性能预期

- **处理时间**：50 万题约 60-120 秒（包含分组和并行处理）
- **内存占用**：约 500MB-1GB
- **准确率**：95%+（取决于参数设置）
- **召回率**：90%+（LSH 可能漏检 5-10%）

---

## 二、数据分组策略

### 2.1 为什么需要分组

- **业务逻辑**：不同题型（单选/多选/判断等）的相同题干不算重复
- **业务逻辑**：不同科目（数学/语文等）的相同题干不算重复
- **性能优化**：分组后每组数据量大幅减少，内存占用降低，便于并行处理

### 2.2 分组维度

按 `(type, subject_id, channel_code)` 三元组分组：

- `type`：题型（1=单选, 2=多选, 3=判断, 4=填空, 8=计算分析）
- `subject_id`：科目 ID
- `channel_code`：渠道代码（可选，根据业务需求决定）

### 2.3 分组查询方式

- **不创建新表或视图**：数据仍在原表 `teach_question`
- **动态分组查询**：通过 SQL WHERE 条件实现分组
- **索引优化**：创建组合索引 `(type, subject_id, channel_code, is_del)` 加速查询

### 2.4 分组统计

假设 50 万题分布：

- 5 种题型 × 10 个科目 × 5 个渠道 = 250 个组合
- 平均每组：50 万 ÷ 250 = 2000 题
- 每组去重：O(2000) vs 整体 O(50 万)

---

## 三、详细实施步骤

### 步骤 0：预处理 - 数据分组

**目标**：将 50 万题按业务逻辑分组，每组分别处理

**操作**：

1. 查询所有分组：`SELECT type, subject_id, channel_code, COUNT(*) FROM teach_question WHERE is_del = 0 GROUP BY type, subject_id, channel_code`
2. 统计每组数量，识别大组和小组
3. 生成分组列表，准备并行处理

**输出**：分组列表，每个分组包含 `(type, subject_id, channel_code, count)`

---

### 步骤 1：清洗题干

**目标**：把所有题干改成统一格式，确保格式一致才能比较

**具体操作**：

1. **去除 HTML 标签**：如果题目内容包含 HTML 标签，需要先去除
2. **全角转半角**：将全角字母、数字、标点转换为半角
3. **空格标准化**：将多个连续空格合并为单个空格，去除首尾空白
4. **图片/公式占位符标准化**：
   - `[图片1]`、`[图片2]` → `[IMG]`
   - `[公式1]`、`[公式2]` → `[FORMULA]`
5. **统一标点符号**：根据需求决定是否统一中文/英文标点
6. **去除不可见字符**：去除控制字符、零宽字符等

**作用**：

- 防止 `"  ABC  "` 和 `"ABC"` 因为几个空格就被当成两道题
- 防止 `[图片1]` 和 `[图片2]` 因为编号不同就被当成不同题
- 确保格式一致才能准确比较

**注意事项**：

- 保留必要的标点符号（可能影响语义）
- 数学公式的处理需要谨慎（可能需要特殊处理）
- 考虑是否统一大小写（中文题目通常不需要）

---

### 步骤 2：秒筛完全一样的题

**目标**：快速找出内容完全相同的题目，这部分可能占重复题的 80%

**具体操作**：

1. 对清洗后的题干计算快速哈希值（MD5 或 SHA256）
2. 按哈希值分组，相同哈希值的题目放入同一组
3. 统计每组数量，数量>1 的组即为完全重复的题目

**技术要点**：

- 使用 MD5 或 SHA256 算法（MD5 更快，50 万题约 1-2 秒）
- 哈希值相同的题目，内容一定完全相同
- 完全重复的题目直接输出结果，不进入后续流程

**输出**：

- 完全重复的题目组列表
- 每组包含的题目 ID 和数量
- 标记为 100%相似度

**性能**：

- 50 万题哈希计算：1-2 秒
- 可能解决 80%的重复问题

---

### 步骤 3：提取特征片段（N-gram）

**目标**：将题目内容切分成小的特征片段，作为计算重复的基础

**具体操作**：

1. **3-gram 提取**：对每道题，按顺序切出所有 3 个字符的小片段
   - 例如："如何比较题库" → `["如何比", "何比较", "较题库"]`
2. **去重处理**：同一题目内的重复片段只算一次（使用集合去重）
3. **短题目处理**：
   - 题目长度 < 3 字符：使用完整文本或降级到 2-gram
   - 题目长度 = 3 字符：直接作为唯一特征

**技术要点**：

- **N-gram 大小**：中文题目推荐 3-gram，英文可考虑 4-gram 或 5-gram
- **去重**：同一题目内的 n-gram 需要去重（使用 set）
- **集合表示**：每道题用 n-gram 集合表示，便于后续计算交集和并集

**作用**：

- 两道题重复程度越高，它们共有的片段就越多
- 这是计算重复的基础，后续通过 Jaccard 相似度计算

**注意事项**：

- 超短题目（<3 字符）需要特殊处理
- 超长题目（>10000 字符）可能需要截断或分段处理

---

### 步骤 4：生成指纹（MinHash）

**目标**：将一道题的几百个 n-gram 片段压缩成固定长度的指纹向量

**具体操作**：

1. **MinHash 算法**：使用 128 个不同的哈希函数（通过种子区分）
2. **计算过程**：
   - 对每个哈希函数，计算所有 n-gram 的哈希值
   - 取每个哈希函数的最小哈希值
   - 128 个哈希函数 → 128 个最小值 → 128 位指纹向量
3. **哈希函数选择**：推荐使用 MurmurHash3（速度快，分布均匀）

**技术要点**：

- **指纹长度**：128 位（可调整，平衡精度和速度）
- **哈希函数**：通过不同的种子（0-127）区分不同的哈希函数
- **压缩效果**：将几百个 n-gram 压缩成 128 个整数

**作用**：

- 把一道题的几百个片段压缩成 128 个数字
- 后面比对数字就行，不用比对几百个片段，速度快
- 相似题目的指纹也会相似（MinHash 的特性）

**替代方案**：

- **SimHash**：Google 使用的算法，实现更简单，但精度略低
- 可根据实际需求选择 MinHash 或 SimHash

---

### 步骤 5：LSH 分桶（局部敏感哈希）

**目标**：将可能重复的题目分到同一个桶中，大幅缩小比对范围

**具体操作**：

1. **Banding 技术**：将 128 位指纹切成 16 段（每段 8 位）
2. **计算桶 ID**：对每一段计算哈希值，得到 16 个桶 ID
3. **分桶逻辑**：
   - 每道题可能出现在 16 个不同的桶中
   - 只要有一个桶 ID 相同，就放入同一个桶
   - 只有桶内的题目才可能重复，不同桶的题目一定不重复
4. **过滤空桶**：只处理桶内题目数量>1 的桶

**技术要点**：

- **参数设置**：128 位指纹 = 16 bands × 8 rows/band
- **多桶策略**：每道题出现在多个桶中，提高召回率
- **桶内比对**：只对桶内的题目进行精确比对

**作用**：

- 把 50 万题的比对范围，缩小到每个桶几十条
- 不同桶的题一定不重复，避免无效比对
- 这是 LSH 的核心：牺牲一些精确度，换取速度

**参数调优**：

- 更多 bands → 更精确但更慢
- 更少 bands → 更快但可能漏检
- 推荐：16 bands × 8 rows/band

---

### 步骤 6：桶内精算重复程度

**目标**：在桶内精确计算每对题目的相似度

**具体操作**：

1. **Jaccard 相似度计算**：
   - 公式：`相似度 = 交集大小 / 并集大小`
   - 交集：两道题共有的 n-gram 数量
   - 并集：两道题所有 n-gram 的总数（去重后）
2. **阈值过滤**：只输出相似度 >= 阈值（如 0.8 或 0.9）的重复对
3. **结果输出**：每对重复题包含题目 ID 和相似度分数

**技术要点**：

- **Jaccard 相似度**：适合集合相似度计算（n-gram 集合）
- **阈值设置**：根据业务需求调整（0.8-0.9 推荐）
- **去重处理**：同一对题目可能出现在多个桶中，需要去重

**输出格式**：

```
{
    "question_id_1": 12345,
    "question_id_2": 67890,
    "similarity": 0.95,
    "group": {
        "type": "1",
        "type_name": "单选题",
        "subject_id": 100,
        "subject_name": "数学",
        "channel_code": "default"
    }
}
```

**替代方案**：

- **编辑距离（Levenshtein）**：更精确但计算更慢
- 可根据需求选择 Jaccard 或编辑距离

---

### 步骤 7：后处理 - 结果汇总

**目标**：合并所有分组的重复结果，生成统一报告

**具体操作**：

1. **合并结果**：将所有分组的重复对合并
2. **去重处理**：同一对题目可能出现在多个桶中，需要去重
3. **添加分组信息**：为每个重复对添加所属分组信息
4. **统计汇总**：
   - 总重复对数
   - 按题型统计
   - 按科目统计
   - 按相似度区间统计
5. **生成报告**：输出文本或 Excel 格式的报告

**输出内容**：

- 重复题目统计摘要
- 重复题目详细列表（包含题目 ID、相似度、分组信息）
- 建议保留的题目 ID（如创建时间最早的）
- 建议删除的题目 ID

---

## 四、完整流程图

```
预处理阶段：数据分组
  ├─ 查询所有分组（按 type, subject_id, channel_code）
  ├─ 统计每组数量
  └─ 生成分组列表

主流程（对每个分组并行执行）：

  第一步：清洗题干
    ├─ 去除HTML标签
    ├─ 全角转半角
    ├─ 空格标准化
    ├─ 图片/公式占位符标准化
    └─ 去除不可见字符

  第二步：秒筛完全一样的题
    ├─ MD5(content) 分组
    ├─ 相同哈希 → 100%重复，直接输出
    └─ 不同哈希 → 进入下一步

  第三步：提取特征片段
    ├─ 3-gram 提取
    ├─ 去重（同一题目内）
    └─ 短题目特殊处理

  第四步：生成指纹
    ├─ MinHash：128个哈希函数
    ├─ 每个函数取最小哈希值
    └─ 生成128位指纹向量

  第五步：LSH分桶
    ├─ 128位切16段（每段8位）
    ├─ 计算16个桶ID
    ├─ 相同桶ID的题目入同一桶
    └─ 只处理桶内题目数>1的桶

  第六步：桶内精算
    ├─ 对桶内每对题目：
    │   ├─ 计算 n-gram 集合的 Jaccard 相似度
    │   └─ 相似度 >= 阈值 → 输出重复对
    └─ 输出：[(id1, id2, similarity), ...]

后处理阶段：结果汇总
  ├─ 合并所有分组的重复结果
  ├─ 去重（同一对可能出现在多个桶中）
  ├─ 添加分组信息
  └─ 生成统一报告
```

---

## 五、技术参数配置

### 5.1 核心参数

| 参数          | 推荐值  | 说明           | 可调整范围 |
| ------------- | ------- | -------------- | ---------- |
| n-gram 大小   | 3       | 中文题目常用   | 2-5        |
| 指纹位数      | 128     | 平衡精度和速度 | 64-256     |
| Band 数量     | 16      | 128 ÷ 8 = 16   | 8-32       |
| Rows per band | 8       | 128 ÷ 16 = 8   | 4-16       |
| 相似度阈值    | 0.8-0.9 | 根据需求调整   | 0.7-0.95   |

### 5.2 性能参数

| 参数       | 推荐值 | 说明                |
| ---------- | ------ | ------------------- |
| 并行进程数 | 8      | 根据 CPU 核心数调整 |
| 批处理大小 | 10000  | 每批处理的题目数    |
| 内存限制   | 1GB    | 单进程内存上限      |

### 5.3 业务参数

| 参数       | 说明                     | 默认值     |
| ---------- | ------------------------ | ---------- |
| 分组维度   | 是否按 channel_code 分组 | 可选       |
| 短题目阈值 | 小于此长度的题目特殊处理 | 3 字符     |
| 长题目阈值 | 大于此长度的题目截断     | 10000 字符 |

---

## 六、边界情况处理

### 6.1 空内容题目

- **情况**：题目内容为空或只有空白字符
- **处理**：跳过该题目，记录日志

### 6.2 超短题目

- **情况**：题目长度 < 3 字符
- **处理**：使用完整文本作为特征，或降级到 2-gram

### 6.3 超长题目

- **情况**：题目长度 > 10000 字符
- **处理**：截断到 10000 字符，或分段处理

### 6.4 特殊字符

- **情况**：包含不可见字符、控制字符等
- **处理**：在清洗阶段去除

### 6.5 编码问题

- **情况**：题目内容编码不一致
- **处理**：统一转换为 UTF-8 编码

### 6.6 小分组处理

- **情况**：某些分组只有几道题
- **处理**：小于 10 题的组，直接使用简单比对，跳过 LSH

---

## 七、性能优化策略

### 7.1 数据库优化

- **创建组合索引**：`CREATE INDEX idx_question_group ON teach_question(type, subject_id, channel_code, is_del)`
- **查询优化**：利用索引加速分组查询和单组数据查询
- **连接池**：使用数据库连接池，避免频繁创建连接

### 7.2 内存优化

- **流式处理**：分批处理题目，避免一次性加载全部数据
- **及时释放**：处理完一组后立即释放内存
- **内存监控**：监控内存使用，避免溢出

### 7.3 并行处理

- **多进程并行**：对不同分组并行处理，充分利用多核 CPU
- **负载均衡**：根据每组数据量分配任务，避免负载不均
- **进度跟踪**：实时显示处理进度，便于监控

### 7.4 算法优化

- **早期退出**：完全重复的题目不进入后续流程
- **缓存优化**：缓存分组列表（如果变化不频繁）
- **批量操作**：批量计算哈希值、批量生成指纹

---

## 八、实施计划

### 阶段一：原型验证（2-3 天）

**目标**：验证算法正确性

**任务**：

1. 实现基础版本（单线程，单分组）
2. 用 1 万题测试验证
3. 调整参数（n-gram 大小、指纹位数等）
4. 验证准确率和召回率

**验收标准**：

- 能够正确识别重复题目
- 相似度计算准确
- 性能满足预期

### 阶段二：完整实现（3-5 天）

**目标**：实现完整功能

**任务**：

1. 添加分组支持
2. 实现并行处理
3. 优化内存使用
4. 添加边界情况处理
5. 50 万题全量测试

**验收标准**：

- 支持多分组并行处理
- 50 万题在 2 分钟内完成
- 内存占用 < 1GB
- 准确率 > 95%

### 阶段三：生产优化（2-3 天）

**目标**：生产环境就绪

**任务**：

1. 添加进度显示和日志
2. 错误处理和异常恢复
3. 结果导出功能（文本/Excel）
4. 性能监控和报告
5. 文档完善

**验收标准**：

- 具备完整的错误处理
- 支持中断恢复
- 结果报告完整清晰
- 文档齐全

---

## 九、预期成果

### 9.1 数据报告

- **重复题目统计摘要**：总重复对数、按题型/科目分布等
- **重复题目详细列表**：每对重复题的 ID、相似度、分组信息
- **处理建议**：建议保留/删除的题目 ID

### 9.2 数据优化

- **减少重复数据**：识别并处理重复题目
- **提高数据质量**：清理冗余数据
- **节省存储空间**：删除重复题目后节省空间

### 9.3 流程改进

- **建立排查机制**：定期执行重复题目排查
- **完善数据规范**：制定题目入库规范，避免重复
- **提升数据质量**：持续优化题库质量

---

## 十、注意事项

### 10.1 数据安全

- **备份数据**：排查前必须备份数据库
- **只读查询**：先只读查询，确认无误后再删除
- **软删除优先**：建议先标记（is_del=1），确认后再硬删除

### 10.2 性能考虑

- **分批处理**：大数据量时建议分批处理
- **监控资源**：监控 CPU、内存、磁盘 IO
- **可中断恢复**：支持中断后从断点继续

### 10.3 参数调优

- **根据数据特点调整**：不同数据可能需要不同参数
- **A/B 测试**：对比不同参数的效果
- **持续优化**：根据实际效果调整参数

### 10.4 结果验证

- **人工复核**：对高相似度的题目进行人工复核
- **抽样检查**：随机抽样检查结果的准确性
- **持续监控**：监控准确率和召回率

---

## 十一、技术参考

### 11.1 核心算法

- **LSH（局部敏感哈希）**：用于快速相似度搜索
- **MinHash**：用于生成指纹向量
- **Jaccard 相似度**：用于计算集合相似度

### 11.2 相关技术

- **N-gram**：文本特征提取
- **哈希算法**：MD5、SHA256、MurmurHash3
- **并行计算**：多进程、多线程

### 11.3 参考资料

- LSH 算法原理和应用
- MinHash 算法详解
- 大规模文本去重技术

---

## 十二、总结

本方案采用**LSH + MinHash**算法，通过"指纹+分桶"的方式，将时间复杂度从 O(n²)降低到 O(n)，能够在 1-2 分钟内处理 50 万条题目，准确率达到 95%+。

**核心优势**：

1. **性能优异**：50 万题 1-2 分钟完成
2. **内存可控**：内存占用约 500MB-1GB
3. **准确率高**：准确率 95%+，召回率 90%+
4. **可扩展性强**：支持并行处理，易于扩展

**关键要点**：

1. 必须先按业务逻辑分组（题型/科目）
2. 多级筛选：哈希 → 指纹 → 分桶 → 精算
3. 参数需要根据实际数据调优
4. 边界情况需要妥善处理

---

**文档版本**：v1.0  
**创建日期**：2024 年  
**最后更新**：2024 年
