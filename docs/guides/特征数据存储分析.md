# 特征数据存储分析

## 📊 数据库表确认

**是的，数据库中有对应的表：`question_dedup_features`**

表结构包括以下字段：
- `cleaned_content` - 清洗后的题目内容
- `content_hash` - 内容哈希值（MD5）
- `ngram_json` - N-gram特征（JSON数组格式）
- `minhash_json` - MinHash指纹（JSON数组格式）
- 其他字段：task_id, question_id, group_type, group_subject_id, group_channel_code, created_at

---

## 🤔 是否有必要存储？

### ✅ 存储的好处

1. **数据分析**
   - 可以分析清洗规则的效果
   - 可以对比不同去重任务的结果
   - 可以优化算法参数

2. **性能优化**
   - 如果题目内容不变，可以复用特征数据
   - 避免重复计算N-gram和MinHash

3. **前端展示**
   - 可以展示清洗后的内容
   - 可以展示相似度计算过程
   - 便于用户理解为什么被判定为重复

4. **问题排查**
   - 当发现重复检测有问题时，可以查看特征数据
   - 便于调试算法

5. **历史记录**
   - 保留每次去重的完整特征数据
   - 支持多次去重结果对比

### ❌ 存储的缺点

1. **数据量巨大**
   - 每个题目一条记录
   - 50万题目 = 50万条记录
   - `cleaned_content`（TEXT字段）可能很大
   - `ngram_json` 和 `minhash_json` 也有一定大小

2. **存储成本**
   - 数据库空间占用大幅增加
   - 如果每次去重都保存，数据会快速增长

3. **处理时间**
   - 写入数据库需要时间
   - 可能影响去重处理速度

4. **实际使用频率**
   - 特征数据可能只在分析时使用
   - 日常查询重复结果时不需要这些数据

---

## 💡 建议方案

### 方案1：不存储特征数据（推荐用于生产环境）

**适用场景**：
- 只需要重复检测结果
- 不需要详细分析和对比
- 数据量很大，存储成本高

**做法**：
- 只存储重复对和重复组
- 特征数据在内存中处理，处理完即丢弃
- 如果需要分析，重新计算一次

### 方案2：选择性存储（推荐用于开发/分析场景）

**适用场景**：
- 需要分析和优化算法
- 需要前端展示清洗后的内容
- 数据量可以接受

**做法**：
- 只存储必要的特征（如 `cleaned_content` 和 `content_hash`）
- 或者只存储部分题目的特征（如只存储重复题目的特征）
- N-gram 和 MinHash 可以按需存储

### 方案3：完全存储（推荐用于研发阶段）

**适用场景**：
- 算法研发和优化阶段
- 需要详细的对比分析
- 数据量可以接受

**做法**：
- 存储所有特征数据
- 包括 cleaned_content, content_hash, ngram_json, minhash_json

---

## 📌 我的建议

根据您的业务需求：

1. **如果主要是生产使用**：建议**不存储**或**只存储必要数据**
   - 只存储 `cleaned_content` 和 `content_hash`（用于展示和简单查询）
   - 不存储 `ngram_json` 和 `minhash_json`（数据量大，使用频率低）

2. **如果需要详细分析**：建议**选择性存储**
   - 存储所有特征数据
   - 或者只存储重复题目的特征数据

3. **如果数据量很大（50万+）**：建议**不存储特征数据**
   - 只存储重复检测结果
   - 特征数据需要时重新计算

---

## 🎯 当前状态

- ✅ 数据库表已创建（`question_dedup_features`）
- ❌ 代码中还未实现存储逻辑
- ⚠️ 需要根据业务需求决定是否存储

---

**建议**：根据您的实际需求选择方案。如果只是生产使用，可以**不存储特征数据**或**只存储必要数据**。

